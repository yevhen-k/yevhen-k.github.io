<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The blog for PhD Yevhen Krasnokutsky | ML Engineer | Data Scientist</title>
    <link>/</link>
    <description>Recent content on The blog for PhD Yevhen Krasnokutsky | ML Engineer | Data Scientist</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 12 Oct 2025 13:40:00 +0300</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Triton. Part 4. Serving RF-DETR</title>
      <link>/series/triton/triton-serving-rf-detr-part-4/</link>
      <pubDate>Sun, 12 Oct 2025 13:40:00 +0300</pubDate>
      <guid>/series/triton/triton-serving-rf-detr-part-4/</guid>
      <description>&lt;h2 id=&#34;tldr-give-me-the-code&#34;&gt;TL;DR: Give Me The Code&lt;/h2&gt;&#xA;&lt;p&gt;If you just want to see the code we discuss today, head over to my GitHub repository at &lt;a href=&#34;https://github.com/yevhen-k/triton-tutorials&#34; target=&#34;_blank&#34;&gt;https://github.com/yevhen-k/triton-tutorials&lt;/a&gt; and check out these files::&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;client-rfdetr-pytorch.py&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;client-rfdetr-pytorch-async.py&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;models/rfdetr-pytorch/&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Today, we&amp;rsquo;re taking a deep dive into several powerful Triton features:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Serving on GPU&lt;/li&gt;&#xA;&lt;li&gt;Model Versioning&lt;/li&gt;&#xA;&lt;li&gt;Batching&lt;/li&gt;&#xA;&lt;li&gt;Asynchronous Serving&lt;/li&gt;&#xA;&lt;li&gt;Passing Custom Parameters&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;By now, you already have a solid foundation: you know how to send and receive custom data, configure the server using &lt;code&gt;config.pbtxt&lt;/code&gt;, start Triton with custom Python logic, and manage data flow.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Triton. Part 3. Working with Images.</title>
      <link>/series/triton/triton-working-with-images-part-3/</link>
      <pubDate>Mon, 22 Sep 2025 11:20:03 +0300</pubDate>
      <guid>/series/triton/triton-working-with-images-part-3/</guid>
      <description>&lt;h2 id=&#34;tldr-give-me-the-code&#34;&gt;TL;DR: Give Me The Code&lt;/h2&gt;&#xA;&lt;p&gt;For full code of the &lt;code&gt;process-image&lt;/code&gt; example, visit &lt;a href=&#34;https://github.com/yevhen-k/triton-tutorials&#34; target=&#34;_blank&#34;&gt;https://github.com/yevhen-k/triton-tutorials&lt;/a&gt; and check the following files and directories:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;client-process-image.py&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;models/process-image&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In this post, we&amp;rsquo;re going to explore how to send and receive images using Triton.&lt;/p&gt;&#xA;&lt;p&gt;In Python and deep learning, images are primarily represented in two ways:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Bytes&lt;/strong&gt;: The raw, encoded data of an image (e.g., a &lt;code&gt;.jpg&lt;/code&gt; or &lt;code&gt;.png&lt;/code&gt; file).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tensors&lt;/strong&gt;: The decoded image data, often a NumPy array or an OpenCV &lt;code&gt;cv::Mat&lt;/code&gt; object, where the image is a multi-dimensional array of pixel values.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Depending on which representation you use, you&amp;rsquo;ll need to configure your Triton server and client differently.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Notes on Validation Dataset Size</title>
      <link>/posts/notes-on-validation-dataset-size/</link>
      <pubDate>Mon, 15 Sep 2025 14:35:19 +0300</pubDate>
      <guid>/posts/notes-on-validation-dataset-size/</guid>
      <description>&lt;link rel=&#34;stylesheet&#34; href=&#34;//cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css&#34;&gt;&#xA;&lt;script src=&#34;//cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js&#34;&gt;&lt;/script&gt;&#xA;&lt;style&gt;&#xA;.katex { font-size: 1.1em; }&#xA;.subtitle {&#xA;    color: var(--text-color);&#xA;    font-style: italic;&#xA;    font-size: 1.2rem;&#xA;    margin-top: 1rem;&#xA;    margin-bottom: .5rem;&#xA;    font-size: 1.5rem;&#xA;    text-align: right;&#xA;}&#xA;&lt;/style&gt;&#xA;&lt;div class=&#34;subtitle&#34;&gt;How Accurate is Your Accuracy?&lt;/div&gt;&#xA;&lt;p&gt;By validation dataset, we mean the specific set of data used to calculate a model&amp;rsquo;s final quality metric. This is where we get the definitive measure of how well our model performs.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;A Quick Note Before We Begin&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;The ideas in this post are specifically for metrics like accuracy, which are based on a series of independent &amp;ldquo;yes&amp;rdquo; or &amp;ldquo;no&amp;rdquo; outcomes. These methods do not apply to &amp;ldquo;aggregated&amp;rdquo; metrics like Mean Squared Error (MSE), Mean Absolute Error (MAE), or Root Mean Squared Error (RMSE). We&amp;rsquo;ll be focusing on a different kind of statistical analysis here.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Triton. Part 2. Echo Json.</title>
      <link>/series/triton/triton-echo-json-part-2/</link>
      <pubDate>Sat, 13 Sep 2025 13:19:58 +0300</pubDate>
      <guid>/series/triton/triton-echo-json-part-2/</guid>
      <description>&lt;h2 id=&#34;tldr-give-me-the-code&#34;&gt;TL;DR: Give Me The Code&lt;/h2&gt;&#xA;&lt;p&gt;For full code of the &lt;code&gt;echo-json&lt;/code&gt; example, please visit &lt;a href=&#34;https://github.com/yevhen-k/triton-tutorials&#34; target=&#34;_blank&#34;&gt;https://github.com/yevhen-k/triton-tutorials&lt;/a&gt; and check the following files and directories:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;client-echo-json.py&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;models/echo-json&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;is-triton-just-for-tensors&#34;&gt;Is Triton Just for Tensors?&lt;/h2&gt;&#xA;&lt;p&gt;In our last post, we made some great progress, learning how to set up and run a simple Triton server to pass a tensor back and forth. But what if a tensor isn&amp;rsquo;t enough?&lt;/p&gt;&#xA;&lt;p&gt;As ML engineers, we often need to send more than just numerical arrays. We might want to send &lt;strong&gt;images&lt;/strong&gt;, &lt;strong&gt;JSON objects&lt;/strong&gt;, or &lt;strong&gt;audio files&lt;/strong&gt; to our models. This brings up a big question: if Triton only deals in tensors, how do we handle all this other data?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Triton. Part 1. Echo Tensor</title>
      <link>/series/triton/triton-echo-tensor-part-1/</link>
      <pubDate>Tue, 09 Sep 2025 20:24:22 +0300</pubDate>
      <guid>/series/triton/triton-echo-tensor-part-1/</guid>
      <description>&lt;h2 id=&#34;tldr-give-me-the-code&#34;&gt;TL;DR: Give Me The Code&lt;/h2&gt;&#xA;&lt;p&gt;For full code of the &lt;code&gt;echo-tensor&lt;/code&gt; example, please visit &lt;a href=&#34;https://github.com/yevhen-k/triton-tutorials&#34; target=&#34;_blank&#34;&gt;https://github.com/yevhen-k/triton-tutorials&lt;/a&gt; and check the following files and directories:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;client-echo-tensor.py&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;models/echo-tensor&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;the-core-concepts-of-triton&#34;&gt;The Core Concepts of Triton&lt;/h2&gt;&#xA;&lt;p&gt;In the following sections we&amp;rsquo;re going to briefly answer on the questions about Triton configuration needed for model serving:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;em&gt;What&lt;/em&gt; needs to be configured?&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;Where&lt;/em&gt; does the configuration happen?&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;How&lt;/em&gt; do we actually configure it?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;tensors-the-heart-of-triton&#34;&gt;Tensors: The Heart of Triton&lt;/h3&gt;&#xA;&lt;p&gt;&lt;em&gt;So, what needs to be configured?&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Triton Intro</title>
      <link>/series/triton/triton-intro/</link>
      <pubDate>Tue, 09 Sep 2025 19:24:22 +0300</pubDate>
      <guid>/series/triton/triton-intro/</guid>
      <description>&lt;h2 id=&#34;my-motivation&#34;&gt;My Motivation&lt;/h2&gt;&#xA;&lt;p&gt;In this new series, I&amp;rsquo;m going to dive into the world of the NVIDIA Triton Inference Server&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. If you&amp;rsquo;re an ML engineer like me, you might have found it tricky to get started with, thanks to the lack of clear examples and tutorials out there. That&amp;rsquo;s exactly why I&amp;rsquo;m writing this &amp;ndash; to help you get the hang of it and use it for your own projects.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-well-be-covering&#34;&gt;What We&amp;rsquo;ll Be Covering&lt;/h2&gt;&#xA;&lt;p&gt;Consider this a mini-course where we&amp;rsquo;ll walk through everything from the basics to more advanced topics. We&amp;rsquo;ll start with setting up your first &amp;ldquo;echo&amp;rdquo; server and understanding the &lt;code&gt;config.pbtxt&lt;/code&gt; file, then work our way up to deploying a deep learning model and benchmarking model ensembles.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Giving Odin Intelligence</title>
      <link>/posts/giving-odin-intelligence/</link>
      <pubDate>Mon, 08 Sep 2025 18:15:24 +0300</pubDate>
      <guid>/posts/giving-odin-intelligence/</guid>
      <description>&lt;p&gt;&lt;em&gt;Initially posted on &lt;a href=&#34;https://dev.to/yevhenk/giving-odin-intelligence-9h0&#34; target=&#34;_blank&#34;&gt;https://dev.to/yevhenk&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;My adventure with Odin keeps going. I decided to try something unexpected with Odin - deep learning and AI! &amp;ldquo;But how?&amp;rdquo; you might ask. Fortunately, there is a well-known deep-learning framework for running AI models. I&amp;rsquo;m about ONNX.&lt;/p&gt;&#xA;&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Familiarity with ONNX&lt;/li&gt;&#xA;&lt;li&gt;Familiarity with C&lt;/li&gt;&#xA;&lt;li&gt;Odin &lt;a href=&#34;https://odin-lang.org/docs/overview&#34; target=&#34;_blank&#34;&gt;Overview&lt;/a&gt; page has been read&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;ONNX has a well-documented C API, which makes it easy to port to Odin.  At least, I hoped it would be easy. But this is another story.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Giving Odin Vision</title>
      <link>/posts/giving-odin-vision/</link>
      <pubDate>Mon, 08 Sep 2025 15:59:27 +0300</pubDate>
      <guid>/posts/giving-odin-vision/</guid>
      <description>&lt;p&gt;&lt;em&gt;Initially posted on &lt;a href=&#34;https://dev.to/yevhenk/giving-odin-vision-1fd5&#34; target=&#34;_blank&#34;&gt;https://dev.to/yevhenk&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;disclaimer&#34;&gt;Disclaimer&lt;/h2&gt;&#xA;&lt;p&gt;This post is about my experience with &lt;a href=&#34;https://odin-lang.org/&#34; target=&#34;_blank&#34;&gt;Odin programming language&lt;/a&gt;. So, I won&amp;rsquo;t talk about its features and advantages and provide basic tutorials. There are plenty of materials on those topics.&lt;/p&gt;&#xA;&lt;h2 id=&#34;prologue&#34;&gt;Prologue&lt;/h2&gt;&#xA;&lt;p&gt;Recently, I was browsing YouTube unconsciously and fell into a pit of recommendations about programming languages. Odin was one of them. Many famous tech YouTubers either talked about Odin or interviewed Ginger Bill (Odin&amp;rsquo;s creator). So, I checked Odin&amp;rsquo;s &lt;a href=&#34;https://odin-lang.org/docs/overview/&#34; target=&#34;_blank&#34;&gt;overwiew&lt;/a&gt; page and found the language interesting to give it a try.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>/about/about/</link>
      <pubDate>Sun, 07 Sep 2025 14:04:11 +0300</pubDate>
      <guid>/about/about/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m Yevhen Krasnokutsky, an experienced AI Team Leader and ML Engineer.&lt;/p&gt;&#xA;&lt;p&gt;My work is centered on developing robust solutions using a variety of technologies, including &lt;strong&gt;Python&lt;/strong&gt;, &lt;strong&gt;C++&lt;/strong&gt;, and &lt;strong&gt;PyTorch&lt;/strong&gt;. I have extensive experience with MLOps and have built a strong command of tools like &lt;strong&gt;Kubeflow&lt;/strong&gt;, &lt;strong&gt;MLFlow&lt;/strong&gt;, &lt;strong&gt;MinIO&lt;/strong&gt;, &lt;strong&gt;Airflow&lt;/strong&gt;, &lt;strong&gt;Triton&lt;/strong&gt;, &lt;strong&gt;KServe&lt;/strong&gt;, and &lt;strong&gt;Ray&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;I have a particular interest in computer vision and cloud technologies. In my free time, I enjoy exploring niche technologies and programming languages outside of the ML and MLOps space.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
